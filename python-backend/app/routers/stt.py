from fastapi import APIRouter, UploadFile, File, HTTPException, Form, Query
from fastapi.responses import PlainTextResponse, JSONResponse
from pathlib import Path
import shutil, time
from typing import List
from app.config import CHUNK_ROOT, MODEL_NAME
from app.services.audio_service import preconvert_webm_to_wav, merge_wavs_in_order
from app.services.io_service import append_index, read_index_unique
from app.services.stt_service import transcribe_ko

router = APIRouter()

@router.get("/healthz")
def healthz():
    return {"status": "ok", "model": MODEL_NAME}

@router.post("/stt/chunk_raw")
async def stt_chunk_raw(
    file: UploadFile = File(...),
    room_no: int = Form(...),
    user_no: int = Form(...),
    seq: int   = Form(...),
    ts_ms: int = Form(...),
):
    room_dir = CHUNK_ROOT / str(room_no)
    room_user_dir = room_dir / str(user_no)
    room_user_dir.mkdir(parents=True, exist_ok=True)
    src = room_user_dir / f"{seq:04d}.webm"
    src.write_bytes(await file.read())
    index_path = room_dir / "index.jsonl"
    append_index(index_path, {"user_no": user_no, "seq": seq, "ts_ms": ts_ms, "path": str(src)})
    pre_wav = room_user_dir / f"{seq:04d}.wav"
    pre_ok = preconvert_webm_to_wav(src, pre_wav)
    return {"ok": True, "saved": str(src), "bytes": src.stat().st_size,
            "wav_preconverted": pre_ok, "wav_path": str(pre_wav) if pre_ok else None}

@router.get("/stt/chunk_index")
def stt_chunk_index(room_no: int = Query(...)):
    room_dir = CHUNK_ROOT / str(room_no)
    index_path = room_dir / "index.jsonl"
    rows = read_index_unique(index_path)
    return {"room_no": room_no, "count": len(rows), "records": rows}

@router.post("/stt/merge_room", response_class=PlainTextResponse)
def stt_merge_room(room_no: int):
    room_dir = CHUNK_ROOT / str(room_no)
    index_path = room_dir / "index.jsonl"
    recs = read_index_unique(index_path)
    wav_parts: List[Path] = []
    for i, r in enumerate(recs):
        src_webm = Path(r["path"])
        if not src_webm.exists(): continue
        pre_wav = src_webm.with_suffix(".wav")
        if not pre_wav.exists() or pre_wav.stat().st_size == 0:
            continue
        wav_parts.append(pre_wav)
    if not wav_parts: raise HTTPException(400, "no wav parts available")
    merged = room_dir / f"room_{room_no}.wav"
    elapsed = merge_wavs_in_order(wav_parts, merged)
    return ("âœ… ë³‘í•© ì™„ë£Œ\n"
            f"- room_no: {room_no}\n"
            f"- ìœ ë‹ˆí¬ ì²­í¬ ìˆ˜: {len(recs)}\n"
            f"- ì‚¬ìš©ëœ wav íŒŒíŠ¸: {len(wav_parts)}\n"
            f"- ê²°ê³¼ íŒŒì¼: {merged}\n"
            f"- â± ë³‘í•© ì†Œìš”: {elapsed:.2f}s\n")

@router.post("/stt/finalize_room", response_class=PlainTextResponse)
def stt_finalize_room(room_no: int):
    t_all = time.time()
    room_dir = CHUNK_ROOT / str(room_no)
    merged = room_dir / f"room_{room_no}.wav"
    t_merge = 0.0
    if not merged.exists() or merged.stat().st_size == 0:
        _ = stt_merge_room(room_no)
        if not merged.exists() or merged.stat().st_size == 0:
            raise HTTPException(400, "merge failed or no merged file")
    text, t_stt = transcribe_ko(merged)
    out_txt = room_dir / f"room_{room_no}.txt"
    out_txt.write_text(text, encoding="utf-8")
    t_total = time.time() - t_all
    head = text[:400].replace("\n", " ")
    return ("âœ… ì „ì‚¬ ì™„ë£Œ (openai-whisper, single-pass)\n"
            f"- model: {MODEL_NAME}\n"
            f"- room_no: {room_no}\n"
            f"- ë³‘í•© íŒŒì¼: {merged}\n"
            f"- í…ìŠ¤íŠ¸ ì €ì¥: {out_txt}\n"
            "\n"
            f"â± ì†Œìš” ì‹œê°„\n"
            f"- ì „ì‚¬: {t_stt:.2f}s\n"
            f"- ì´í•©: {t_total:.2f}s\n"
            "\në¯¸ë¦¬ë³´ê¸°(400ì):\n" + head + "\n")

@router.delete("/stt/reset_room", response_class=PlainTextResponse)
def stt_reset_room(room_no: int):
    room_dir = CHUNK_ROOT / str(room_no)
    if room_dir.exists():
        shutil.rmtree(room_dir)
    return f"ğŸ§¹ ë°© {room_no} ë°ì´í„° ì‚­ì œ ì™„ë£Œ"
